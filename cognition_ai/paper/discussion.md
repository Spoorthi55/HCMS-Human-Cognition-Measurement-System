# Discussion

This study examined whether static correctness-based assessments are sufficient indicators of true understanding. The results suggest that they are not. Learners with comparable accuracy profiles often exhibited substantially different cognitive stability and calibration behaviors, indicating that correctness alone can obscure meaningful variation in underlying understanding.

The findings reinforce a key insight from cognitive science: performance outcomes and cognitive states are not equivalent. While accuracy reflects observable behavior, it does not reliably capture the robustness, coherence, or self-awareness of a learner’s knowledge.

## Rethinking Mastery Beyond Accuracy

The observed divergence between accuracy and cognitive stability challenges a long-standing assumption in assessment design—that correct answers reliably signal mastery. The results show that learners may answer correctly while exhibiting unstable reasoning, inconsistent confidence, or fragile understanding that degrades under minimal perturbation.

HCMS captures these latent properties by modeling cognition as a multi-dimensional construct rather than a single performance score. This shift enables assessment systems to distinguish between robust understanding and brittle correctness, even when surface-level outcomes appear identical. In this sense, mastery is better characterized as a property of stability and calibration, not correctness alone.

## The Role of Confidence Calibration

Confidence–accuracy alignment emerged as a particularly informative signal across experiments. Learners exhibiting systematic overconfidence or underconfidence demonstrated greater instability under perturbation, suggesting that metacognitive awareness is closely tied to cognitive robustness.

This finding aligns with prior work in educational psychology linking metacognitive monitoring to learning outcomes, while extending it by operationalizing calibration as a measurable, system-level signal. Importantly, HCMS does not treat confidence as an auxiliary or cosmetic feature, but as a core component of cognitive state estimation that directly influences stability and robustness.

## Implications for Assessment Systems

These findings have practical implications for the design of intelligent assessment and learning systems. If mastery is defined solely by correctness, systems risk overlooking learners who appear competent but lack stable understanding, as well as mischaracterizing learners with emerging but coherent reasoning.

Cognition-aware assessment enables:
- Earlier detection of misconceptions and fragile understanding
- More targeted and fair intervention strategies
- Improved differentiation between learning states with similar performance
- More faithful evaluation of learner progress over time

HCMS demonstrates that such assessment is feasible using interpretable, modular components rather than opaque black-box models, supporting transparency and diagnostic validity.

# Limitations and Scope

This work represents an initial investigation conducted under controlled experimental conditions. HCMS is currently evaluated as a research prototype rather than a deployed educational system, and the findings should be interpreted accordingly.

The experiments do not involve large-scale real-user deployment, longitudinal classroom integration, or high-stakes assessment scenarios. Learner populations and task domains are limited, and the perturbations applied are deliberately minimal and controlled. As such, the results provide directional evidence about cognitive stability and calibration rather than universal claims about learning behavior.

The purpose of this work is not to propose a complete replacement for existing assessment frameworks, but to demonstrate that correctness-based evaluation alone is insufficient for capturing key properties of understanding. HCMS should be viewed as a measurement instrument for probing cognitive validity, not as a comprehensive learner model.

These limitations define the scope of the present contribution and motivate future extensions rather than detract from the core findings.

## Future Directions

Future research will extend this work by:
- Tracking cognitive stability longitudinally across learning trajectories
- Evaluating cross-domain generalization of cognition signals
- Incorporating synthetic learner simulations for controlled analysis
- Integrating HCMS into real-world educational platforms

By focusing on how learners think rather than what they answer, cognition-aware assessment systems such as HCMS offer a path toward more accurate, transparent, and human-aligned evaluation of understanding.
